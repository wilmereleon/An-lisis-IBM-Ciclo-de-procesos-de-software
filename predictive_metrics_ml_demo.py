# predictive_metrics_ml_demo.py
# Sistema ML para predicci√≥n y detecci√≥n de anomal√≠as en m√©tricas de calidad IBM
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import random
import json
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')

# Simulamos las librer√≠as de ML (en producci√≥n ser√≠an sklearn, prophet, etc.)
class MockRandomForestRegressor:
    def __init__(self, n_estimators=100, max_depth=10, random_state=42):
        self.params = {'n_estimators': n_estimators, 'max_depth': max_depth}
        
    def fit(self, X, y):
        self.feature_count = X.shape[1] if len(X.shape) > 1 else 1
        return self
        
    def predict(self, X):
        # Simulaci√≥n de predicci√≥n realista con variabilidad
        base_prediction = random.uniform(0.8, 1.2)
        return np.array([base_prediction])

class MockIsolationForest:
    def __init__(self, contamination=0.1, random_state=42):
        self.contamination = contamination
        
    def fit(self, X):
        return self
        
    def predict(self, X):
        # 10% probabilidad de anomal√≠a
        return np.array([-1 if random.random() < 0.1 else 1])
        
    def decision_function(self, X):
        return np.array([random.uniform(-0.5, 0.5)])

class MockStandardScaler:
    def fit_transform(self, X):
        return X
        
    def transform(self, X):
        return X

class MockProphet:
    def __init__(self, daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=False):
        self.seasonality = {'daily': daily_seasonality, 'weekly': weekly_seasonality}
        
    def fit(self, df):
        return self
        
    def predict(self, future_df):
        base_value = random.uniform(80, 95)
        return pd.DataFrame({
            'yhat': [base_value],
            'yhat_lower': [base_value - 5],
            'yhat_upper': [base_value + 5]
        })

class PredictiveQualityAnalyticsDemo:
    """
    Demo del sistema de ML para predicci√≥n y detecci√≥n de anomal√≠as en m√©tricas de calidad
    Simula capacidades de ML avanzadas para predecir problemas de calidad
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.anomaly_detectors = {}
        self.training_completed = False
        
    def generate_historical_data(self, days: int = 90) -> pd.DataFrame:
        """Genera datos hist√≥ricos simulados para entrenamiento"""
        print("üîÑ Generando datos hist√≥ricos para entrenamiento ML...")
        
        dates = pd.date_range(start=datetime.now() - timedelta(days=days), 
                             end=datetime.now(), freq='H')
        
        # Simular tendencias realistas con patrones y estacionalidad
        data = []
        for i, date in enumerate(dates):
            # A√±adir patrones de negocio (peor calidad en releases, mejor en fines de semana)
            week_factor = 0.95 if date.weekday() < 5 else 1.05  # Peor en d√≠as laborales
            hour_factor = 0.98 if 9 <= date.hour <= 17 else 1.02  # Peor en horas laborales
            
            # Simular degradaci√≥n gradual seguida de mejora (ciclos de release)
            cycle_factor = 0.95 + 0.1 * np.sin(i / 168)  # Ciclo semanal
            
            base_noise = random.uniform(0.95, 1.05)
            trend_factor = week_factor * hour_factor * cycle_factor * base_noise
            
            row = {
                'timestamp': date,
                'defect_density': max(0.5, 2.0 * trend_factor + random.uniform(-0.3, 0.3)),
                'pipeline_success_rate': min(100, 95.0 * (2 - trend_factor) + random.uniform(-2, 2)),
                'lead_time': max(1.0, 4.0 * trend_factor + random.uniform(-1, 1)),
                'customer_satisfaction': min(5.0, 4.2 * (2 - trend_factor) + random.uniform(-0.2, 0.2)),
                'availability': min(100, 99.0 * (2 - trend_factor) + random.uniform(-0.5, 0.5)),
                'security_score': min(10, 8.5 * (2 - trend_factor) + random.uniform(-0.5, 0.5)),
                'code_coverage': min(100, 85.0 * (2 - trend_factor) + random.uniform(-3, 3)),
                'deployment_frequency': max(0.1, 1.5 * (2 - trend_factor) + random.uniform(-0.3, 0.3))
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        print(f"‚úÖ Generados {len(df)} puntos de datos hist√≥ricos")
        print(f"   üìÖ Per√≠odo: {df['timestamp'].min()} a {df['timestamp'].max()}")
        return df
        
    def train_predictive_models(self, historical_data: pd.DataFrame):
        """Entrena modelos predictivos para cada m√©trica cr√≠tica"""
        print("\nü§ñ Iniciando entrenamiento de modelos de Machine Learning...")
        print("=" * 60)
        
        critical_metrics = [
            'defect_density', 'pipeline_success_rate', 'lead_time',
            'customer_satisfaction', 'availability', 'security_score'
        ]
        
        for metric in critical_metrics:
            if metric in historical_data.columns:
                print(f"üîß Entrenando modelo para: {metric}")
                
                # Crear features (simulado)
                features = self._create_features(historical_data, metric)
                target = historical_data[metric].shift(-1).dropna()
                features = features.iloc[:-1]
                
                # Entrenar modelo Random Forest
                scaler = MockStandardScaler()
                features_scaled = scaler.fit_transform(features)
                self.scalers[metric] = scaler
                
                model = MockRandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
                model.fit(features_scaled, target)
                self.models[metric] = model
                
                # Entrenar detector de anomal√≠as
                anomaly_detector = MockIsolationForest(contamination=0.1, random_state=42)
                anomaly_detector.fit(features_scaled)
                self.anomaly_detectors[metric] = anomaly_detector
                
                # Entrenar modelo Prophet para tendencias
                prophet_model = MockProphet(daily_seasonality=True, weekly_seasonality=True)
                prophet_model.fit(pd.DataFrame())  # Simulado
                self.models[f"{metric}_prophet"] = prophet_model
                
                print(f"   ‚úÖ Modelo {metric}: Random Forest + Isolation Forest + Prophet")
        
        self.training_completed = True
        print(f"\nüéØ Entrenamiento completado para {len(critical_metrics)} m√©tricas")
        print("   üìä Algoritmos: Random Forest + Isolation Forest + Prophet")
        print("   üîç Capacidades: Predicci√≥n + Detecci√≥n de Anomal√≠as + Tendencias")
        
    def _create_features(self, data: pd.DataFrame, metric: str) -> pd.DataFrame:
        """Crea features para el modelo ML"""
        # Simulamos features t√≠picas de series temporales
        features = pd.DataFrame({
            'hour': data['timestamp'].dt.hour,
            'day_of_week': data['timestamp'].dt.dayofweek,
            'is_weekend': (data['timestamp'].dt.dayofweek >= 5).astype(int),
            'rolling_mean_7d': data[metric].rolling(168).mean().fillna(data[metric].mean()),
            'rolling_std_7d': data[metric].rolling(168).std().fillna(0),
            'lag_1h': data[metric].shift(1).fillna(data[metric].mean()),
            'lag_24h': data[metric].shift(24).fillna(data[metric].mean())
        })
        return features.fillna(0)
        
    def _calculate_prediction_confidence(self, model, features) -> Dict[str, float]:
        """Calcula intervalo de confianza de la predicci√≥n"""
        return {
            'confidence': random.uniform(0.75, 0.95),
            'lower_bound': random.uniform(0.8, 0.9),
            'upper_bound': random.uniform(1.1, 1.2)
        }
    
    def predict_next_period(self, current_data: pd.DataFrame) -> Dict[str, Dict]:
        """Predice valores de m√©tricas para el siguiente per√≠odo"""
        if not self.training_completed:
            raise ValueError("Modelos no han sido entrenados")
            
        print("\nüîÆ Generando predicciones con Machine Learning...")
        print("-" * 50)
        
        predictions = {}
        
        critical_metrics = ['defect_density', 'pipeline_success_rate', 'lead_time',
                          'customer_satisfaction', 'availability', 'security_score']
        
        for metric in critical_metrics:
            if metric in self.models:
                try:
                    # Predicci√≥n con Random Forest
                    features = self._create_features(current_data, metric)
                    features_scaled = self.scalers[metric].transform(features)
                    
                    prediction = self.models[metric].predict(features_scaled[-1:])
                    confidence = self._calculate_prediction_confidence(self.models[metric], features_scaled[-1:])
                    
                    # Detecci√≥n de anomal√≠as
                    anomaly_score = self.anomaly_detectors[metric].decision_function(features_scaled[-1:])
                    is_anomaly = self.anomaly_detectors[metric].predict(features_scaled[-1:]) == -1
                    
                    # Predicci√≥n de tendencia con Prophet
                    prophet_forecast = self.models[f"{metric}_prophet"].predict(pd.DataFrame())
                    
                    # Simular valores realistas basados en m√©trica
                    predicted_value = self._simulate_realistic_prediction(metric, current_data[metric].iloc[-1])
                    
                    predictions[metric] = {
                        'current_value': float(current_data[metric].iloc[-1]),
                        'predicted_value': predicted_value,
                        'confidence_interval': confidence,
                        'anomaly_score': float(anomaly_score[0]),
                        'is_anomaly': bool(is_anomaly[0]),
                        'trend_forecast': {
                            'value': float(prophet_forecast['yhat'].iloc[0]),
                            'lower_bound': float(prophet_forecast['yhat_lower'].iloc[0]),
                            'upper_bound': float(prophet_forecast['yhat_upper'].iloc[0])
                        },
                        'change_percentage': ((predicted_value - current_data[metric].iloc[-1]) / current_data[metric].iloc[-1]) * 100,
                        'recommendation': self._generate_recommendation(metric, predicted_value, is_anomaly[0])
                    }
                    
                    status = "üö® ANOMAL√çA" if is_anomaly[0] else "‚úÖ NORMAL"
                    change = predictions[metric]['change_percentage']
                    trend = "üìà" if change > 0 else "üìâ" if change < 0 else "‚û°Ô∏è"
                    
                    print(f"{status} {metric}: {predicted_value:.2f} {trend} ({change:+.1f}%)")
                    
                except Exception as e:
                    print(f"‚ùå Error prediciendo {metric}: {e}")
                    continue
        
        print(f"\nüéØ Predicciones generadas para {len(predictions)} m√©tricas")
        return predictions
    
    def _simulate_realistic_prediction(self, metric: str, current_value: float) -> float:
        """Simula predicciones realistas basadas en la m√©trica"""
        # Tendencias t√≠picas por m√©trica
        trends = {
            'defect_density': random.uniform(0.95, 1.05),  # Relativamente estable
            'pipeline_success_rate': random.uniform(0.98, 1.02),  # Muy estable
            'lead_time': random.uniform(0.9, 1.15),  # Puede variar m√°s
            'customer_satisfaction': random.uniform(0.95, 1.05),  # Estable
            'availability': random.uniform(0.995, 1.005),  # Muy estable
            'security_score': random.uniform(0.98, 1.02)  # Estable
        }
        
        trend_factor = trends.get(metric, random.uniform(0.95, 1.05))
        return current_value * trend_factor
    
    def _generate_recommendation(self, metric: str, predicted_value: float, is_anomaly: bool) -> str:
        """Genera recomendaciones basadas en predicciones"""
        recommendations = {
            'defect_density': "Revisar code reviews y testing pre-commit",
            'pipeline_success_rate': "Optimizar scripts CI/CD y infraestructura",
            'lead_time': "Analizar bottlenecks en proceso de desarrollo",
            'customer_satisfaction': "Revisar UX y performance de aplicaciones",
            'availability': "Fortalecer monitoring y recovery procedures",
            'security_score': "Ejecutar security audit y patch management"
        }
        
        base_rec = recommendations.get(metric, "Monitorear tendencia y ajustar procesos")
        
        if is_anomaly:
            return f"üö® URGENTE: {base_rec} - Patr√≥n an√≥malo detectado"
        else:
            return f"üìä {base_rec}"
    
    def detect_quality_risks(self, predictions: Dict) -> List[Dict]:
        """Detecta riesgos de calidad basado en predicciones ML"""
        print("\n‚ö†Ô∏è  Detectando riesgos de calidad con ML...")
        print("-" * 40)
        
        risks = []
        
        # Umbrales cr√≠ticos por m√©trica
        risk_rules = {
            'defect_density': {'threshold': 2.5, 'direction': 'above', 'impact': 'HIGH'},
            'pipeline_success_rate': {'threshold': 95.0, 'direction': 'below', 'impact': 'MEDIUM'},
            'customer_satisfaction': {'threshold': 4.0, 'direction': 'below', 'impact': 'HIGH'},
            'availability': {'threshold': 99.0, 'direction': 'below', 'impact': 'CRITICAL'},
            'security_score': {'threshold': 8.0, 'direction': 'below', 'impact': 'CRITICAL'},
            'lead_time': {'threshold': 7.0, 'direction': 'above', 'impact': 'MEDIUM'}
        }
        
        for metric, prediction in predictions.items():
            if metric in risk_rules:
                rule = risk_rules[metric]
                predicted_value = prediction['predicted_value']
                current_value = prediction['current_value']
                
                # Evaluar riesgo basado en predicci√≥n
                risk_detected = False
                if rule['direction'] == 'above' and predicted_value > rule['threshold']:
                    risk_detected = True
                elif rule['direction'] == 'below' and predicted_value < rule['threshold']:
                    risk_detected = True
                
                # Tambi√©n considerar anomal√≠as como riesgo
                if prediction['is_anomaly']:
                    risk_detected = True
                
                if risk_detected:
                    # Calcular tiempo estimado hasta el umbral
                    change_rate = abs(predicted_value - current_value)
                    time_to_threshold = self._calculate_time_to_threshold(
                        current_value, predicted_value, rule['threshold'], change_rate
                    )
                    
                    risk = {
                        'metric': metric,
                        'current_value': current_value,
                        'predicted_value': predicted_value,
                        'threshold': rule['threshold'],
                        'current_trend': 'DETERIORATING' if (
                            (rule['direction'] == 'above' and predicted_value > current_value) or
                            (rule['direction'] == 'below' and predicted_value < current_value)
                        ) else 'IMPROVING',
                        'impact': rule['impact'],
                        'confidence': prediction['confidence_interval']['confidence'],
                        'time_to_threshold': time_to_threshold,
                        'is_anomaly_based': prediction['is_anomaly'],
                        'recommended_actions': self._get_mitigation_actions(metric, rule['impact']),
                        'risk_score': self._calculate_risk_score(prediction, rule)
                    }
                    
                    risks.append(risk)
                    
                    risk_icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[rule['impact']]
                    print(f"{risk_icon} {rule['impact']}: {metric} - {predicted_value:.2f} (umbral: {rule['threshold']})")
        
        # Ordenar por impacto y score de riesgo
        risks_sorted = sorted(risks, key=lambda x: (
            {'CRITICAL': 4, 'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}[x['impact']], 
            x['risk_score']
        ), reverse=True)
        
        if not risks_sorted:
            print("‚úÖ No se detectaron riesgos cr√≠ticos en las predicciones")
        else:
            print(f"‚ö†Ô∏è  {len(risks_sorted)} riesgos detectados requieren atenci√≥n")
        
        return risks_sorted
    
    def _calculate_time_to_threshold(self, current: float, predicted: float, threshold: float, change_rate: float) -> str:
        """Calcula tiempo estimado hasta alcanzar el umbral"""
        if change_rate == 0:
            return "Estable"
        
        distance_to_threshold = abs(threshold - current)
        hours_to_threshold = distance_to_threshold / change_rate
        
        if hours_to_threshold < 24:
            return f"{int(hours_to_threshold)} horas"
        elif hours_to_threshold < 168:
            return f"{int(hours_to_threshold/24)} d√≠as"
        else:
            return f"{int(hours_to_threshold/168)} semanas"
    
    def _get_mitigation_actions(self, metric: str, impact: str) -> List[str]:
        """Define acciones de mitigaci√≥n por m√©trica e impacto"""
        actions = {
            'defect_density': [
                "Incrementar frequency de code reviews",
                "Fortalecer unit testing coverage",
                "Implementar static code analysis autom√°tico",
                "Training en best practices de desarrollo"
            ],
            'pipeline_success_rate': [
                "Revisar y optimizar scripts de CI/CD",
                "Mejorar stability de infraestructura de testing",
                "Implementar retry logic inteligente",
                "Monitoreo proactivo de pipeline health"
            ],
            'customer_satisfaction': [
                "An√°lisis de feedback y tickets de soporte",
                "Optimizaci√≥n de performance de aplicaciones",
                "Mejoras de UX basadas en user analytics",
                "Comunicaci√≥n proactiva con usuarios"
            ],
            'availability': [
                "Revisi√≥n de SLA y escalation procedures",
                "Implementaci√≥n de chaos engineering",
                "Mejora de monitoring y alerting",
                "Disaster recovery testing"
            ],
            'security_score': [
                "Security audit completo inmediato",
                "Patch management acelerado",
                "Penetration testing",
                "Security awareness training"
            ]
        }
        
        base_actions = actions.get(metric, ["Monitoreo continuo", "An√°lisis de root cause"])
        
        if impact == 'CRITICAL':
            return ["üö® ACCI√ìN INMEDIATA: " + action for action in base_actions[:2]]
        elif impact == 'HIGH':
            return ["‚ö†Ô∏è PRIORIDAD ALTA: " + action for action in base_actions[:3]]
        else:
            return ["üìã " + action for action in base_actions]
    
    def _calculate_risk_score(self, prediction: Dict, rule: Dict) -> float:
        """Calcula score de riesgo basado en m√∫ltiples factores"""
        # Factores: distancia al umbral, confianza, anomal√≠a, tendencia
        threshold_distance = abs(prediction['predicted_value'] - rule['threshold']) / rule['threshold']
        confidence_factor = prediction['confidence_interval']['confidence']
        anomaly_factor = 2.0 if prediction['is_anomaly'] else 1.0
        change_factor = abs(prediction['change_percentage']) / 100
        
        risk_score = (threshold_distance * confidence_factor * anomaly_factor * (1 + change_factor)) * 100
        return min(100, risk_score)
    
    def generate_ml_insights_report(self, predictions: Dict, risks: List[Dict]) -> str:
        """Genera reporte de insights de ML"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        total_predictions = len(predictions)
        anomalies_detected = sum(1 for p in predictions.values() if p['is_anomaly'])
        critical_risks = len([r for r in risks if r['impact'] == 'CRITICAL'])
        high_risks = len([r for r in risks if r['impact'] == 'HIGH'])
        
        risk_status = "üî¥ ALTO RIESGO" if critical_risks > 0 else \
                     "üü° RIESGO MODERADO" if high_risks > 0 else \
                     "üü¢ BAJO RIESGO"
        
        report = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                        IBM ML QUALITY ANALYTICS REPORT                   ‚ïë
‚ïë                     Predicciones y An√°lisis de Riesgos                   ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Timestamp: {timestamp}                                       ‚ïë
‚ïë Estado de Riesgo: {risk_status}                                         ‚ïë
‚ïë Predicciones: {total_predictions} | Anomal√≠as: {anomalies_detected} | Riesgos Cr√≠ticos: {critical_risks}            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

ü§ñ PREDICCIONES DE MACHINE LEARNING
{'‚ïê' * 50}"""

        for metric, pred in predictions.items():
            change = pred['change_percentage']
            trend_icon = "üìà" if change > 0 else "üìâ" if change < 0 else "‚û°Ô∏è"
            anomaly_icon = "üö®" if pred['is_anomaly'] else "‚úÖ"
            
            report += f"""
{anomaly_icon} {metric.upper().replace('_', ' ')}:
   Actual: {pred['current_value']:.2f} ‚Üí Predicci√≥n: {pred['predicted_value']:.2f} {trend_icon}
   Cambio: {change:+.1f}% | Confianza: {pred['confidence_interval']['confidence']:.1%}
   Tendencia: {pred['trend_forecast']['value']:.2f} ¬±{pred['trend_forecast']['upper_bound'] - pred['trend_forecast']['value']:.2f}
   Recomendaci√≥n: {pred['recommendation']}
"""

        if risks:
            report += f"\n‚ö†Ô∏è  RIESGOS DETECTADOS POR ML ({len(risks)})\n" + "‚ïê" * 40
            
            for i, risk in enumerate(risks, 1):
                impact_icon = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[risk['impact']]
                
                report += f"""
{i}. {impact_icon} {risk['impact']}: {risk['metric'].upper().replace('_', ' ')}
   Valor Actual: {risk['current_value']:.2f}
   Predicci√≥n: {risk['predicted_value']:.2f} (Umbral: {risk['threshold']})
   Tendencia: {risk['current_trend']}
   Tiempo a Umbral: {risk['time_to_threshold']}
   Risk Score: {risk['risk_score']:.1f}/100
   Confianza: {risk['confidence']:.1%}
   
   üõ†Ô∏è  ACCIONES RECOMENDADAS:"""
                
                for action in risk['recommended_actions']:
                    report += f"\n      ‚Ä¢ {action}"
                
                report += "\n"
        
        else:
            report += "\n‚úÖ NO HAY RIESGOS CR√çTICOS DETECTADOS\n" + "‚ïê" * 40
            report += "\nTodas las m√©tricas se mantienen dentro de rangos aceptables seg√∫n ML."

        report += f"""

üîÆ PREDICCIONES CLAVE PARA PR√ìXIMAS 24H
{'‚ïê' * 45}
üéØ M√©tricas Mejorar√°n: {len([p for p in predictions.values() if p['change_percentage'] > 0])}
üìâ M√©tricas Empeorar√°n: {len([p for p in predictions.values() if p['change_percentage'] < 0])}
üö® Anomal√≠as Esperadas: {anomalies_detected}
‚ö†Ô∏è  Riesgos a Monitorear: {len(risks)}

üìä MODELOS ML UTILIZADOS
{'‚ïê' * 30}
üå≥ Random Forest: Predicciones de valores futuros
üîç Isolation Forest: Detecci√≥n de anomal√≠as
üìà Prophet: An√°lisis de tendencias y estacionalidad
üéØ Risk Engine: Scoring integrado de riesgos

üîÑ PR√ìXIMAS ACCIONES AUTOM√ÅTICAS
{'‚ïê' * 35}
‚Ä¢ Re-entrenamiento de modelos: 24 horas
‚Ä¢ Predicciones actualizadas: 1 hora
‚Ä¢ Alertas ML autom√°ticas: Tiempo real
‚Ä¢ Dashboard ML: http://ibm-ml-dashboard.internal

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Generado por: IBM ML Quality Analytics Engine v3.0
Algoritmos: scikit-learn + Prophet + TensorFlow
        """
        
        return report

def main_ml_demo():
    """Funci√≥n principal para demostrar el sistema ML"""
    print("üöÄ SISTEMA DE ANALYTICS PREDICTIVO CON MACHINE LEARNING")
    print("=" * 70)
    print("üß† Entrenando modelos para predecir problemas de calidad...")
    
    # Crear instancia del sistema ML
    analytics = PredictiveQualityAnalyticsDemo()
    
    # Generar y entrenar con datos hist√≥ricos
    historical_data = analytics.generate_historical_data(days=90)
    analytics.train_predictive_models(historical_data)
    
    # Simular datos actuales (√∫ltimas 24 horas)
    current_data = historical_data.tail(24).copy()
    current_data['timestamp'] = pd.date_range(start=datetime.now() - timedelta(hours=23),
                                             end=datetime.now(), freq='H')
    
    # Generar predicciones
    predictions = analytics.predict_next_period(current_data)
    
    # Detectar riesgos
    risks = analytics.detect_quality_risks(predictions)
    
    # Generar reporte completo
    print("\n" + "=" * 70)
    print(analytics.generate_ml_insights_report(predictions, risks))
    
    # Simular salida de datos
    print("\nüíæ DATOS ML EXPORTADOS:")
    print("-" * 30)
    print(f"ü§ñ Modelos: ml_models_{datetime.now().strftime('%Y%m%d')}.pkl")
    print(f"üîÆ Predicciones: predictions_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
    print(f"‚ö†Ô∏è  Riesgos: risks_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.json")
    print(f"üìä ML Dashboard: http://ibm-ml-dashboard.internal/live")

if __name__ == "__main__":
    main_ml_demo()