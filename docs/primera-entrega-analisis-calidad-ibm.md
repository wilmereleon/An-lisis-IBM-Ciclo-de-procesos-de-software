# Primera Entrega: An√°lisis de Modelos de Calidad de Software para IBM

## Tabla de Contenido

1. [Introducci√≥n](#1-introducci√≥n)
2. [Elementos de Modelos de Calidad de Software](#2-elementos-de-modelos-de-calidad-de-software)
3. [Comparativo de Modelos de Calidad](#3-comparativo-de-modelos-de-calidad)
4. [An√°lisis de Pros y Contras](#4-an√°lisis-de-pros-y-contras)
5. [An√°lisis DOFA de IBM](#5-an√°lisis-dofa-de-ibm)
6. [Criterios de Validaci√≥n del Estado Empresarial](#6-criterios-de-validaci√≥n-del-estado-empresarial)
7. [Selecci√≥n de Modelos M√°s Adecuados](#7-selecci√≥n-de-modelos-m√°s-adecuados)
8. [Tabla de Procesos de Pruebas por Ciclo de Vida](#8-tabla-de-procesos-de-pruebas-por-ciclo-de-vida)
9. [Conclusiones](#9-conclusiones)

---

## 1. Introducci√≥n

El presente documento constituye la primera entrega del an√°lisis de modelos de calidad de software aplicables a IBM, con el objetivo de identificar los marcos de trabajo m√°s adecuados para mejorar la calidad en el desarrollo de productos de software tanto internos como externos.

IBM, como l√≠der global en tecnolog√≠a empresarial, requiere un enfoque sistem√°tico y bien fundamentado para la implementaci√≥n de modelos de calidad que permitan optimizar sus procesos de desarrollo, reducir costos operacionales y mejorar la satisfacci√≥n del cliente.

**Objetivos Espec√≠ficos:**
- Analizar elementos clave de diversos modelos de calidad de software
- Realizar comparativo t√©cnico-econ√≥mico entre modelos
- Identificar fortalezas, debilidades, oportunidades y amenazas de IBM
- Establecer criterios de validaci√≥n basados en KPA y otros factores cr√≠ticos
- Seleccionar los dos modelos m√°s adecuados para IBM
- Desarrollar tabla de procesos de pruebas por fase del ciclo de vida

---

## 2. Elementos de Modelos de Calidad de Software

### 2.1 CMMI (Capability Maturity Model Integration)

**Elementos Clave:**
- **√Åreas de Proceso Clave (KPA):** 22 √°reas organizadas en 5 niveles de madurez
- **Niveles de Madurez:** Inicial (1), Gestionado (2), Definido (3), Cuantitativamente Gestionado (4), Optimizado (5)
- **Representaciones:** Continua (por √°rea de proceso) y por etapas (por nivel de madurez)
- **Pr√°cticas Espec√≠ficas (SP):** Actividades concretas para implementar cada √°rea de proceso
- **Pr√°cticas Gen√©ricas (GP):** Aplicables a todas las √°reas de proceso

**Componentes T√©cnicos:**
- Gesti√≥n de Requisitos (REQM)
- Planificaci√≥n de Proyectos (PP)
- Seguimiento y Control de Proyectos (PMC)
- Gesti√≥n de Configuraci√≥n (CM)
- Aseguramiento de la Calidad (PPQA)

### 2.2 TMMi (Test Maturity Model Integration)

**Elementos Clave:**
- **Niveles de Madurez:** 5 niveles espec√≠ficos para testing
- **√Åreas de Proceso de Testing:** 16 √°reas especializadas en pruebas
- **Objetivos de Testing:** Definidos por nivel de madurez
- **Pr√°cticas de Testing:** Espec√≠ficas y gen√©ricas para pruebas

**Componentes T√©cnicos:**
- Pol√≠tica y Estrategia de Testing (Test Policy and Strategy)
- Planificaci√≥n de Testing (Test Planning)
- Seguimiento y Control de Testing (Test Monitoring and Control)
- Dise√±o y Ejecuci√≥n de Testing (Test Design and Execution)
- Ambiente de Testing (Test Environment)

### 2.3 ISO/IEC 25010 (SQuaRE)

**Elementos Clave:**
- **Caracter√≠sticas de Calidad:** 8 caracter√≠sticas principales
- **Sub-caracter√≠sticas:** 31 sub-caracter√≠sticas espec√≠ficas
- **M√©tricas de Calidad:** Medidas cuantificables para cada caracter√≠stica
- **Modelo de Calidad en Uso:** Enfoque en la experiencia del usuario

**Componentes T√©cnicos:**
- Adecuaci√≥n Funcional (Functional Suitability)
- Eficiencia de Desempe√±o (Performance Efficiency)
- Compatibilidad (Compatibility)
- Usabilidad (Usability)
- Confiabilidad (Reliability)
- Seguridad (Security)
- Mantenibilidad (Maintainability)
- Portabilidad (Portability)

### 2.4 Six Sigma

**Elementos Clave:**
- **Metodolog√≠a DMAIC:** Define, Measure, Analyze, Improve, Control
- **Niveles de Calidad:** Medidos en defectos por mill√≥n de oportunidades (DPMO)
- **Roles Definidos:** Green Belt, Black Belt, Master Black Belt
- **Herramientas Estad√≠sticas:** Control estad√≠stico de procesos

**Componentes T√©cnicos:**
- Mapeo de Procesos (Process Mapping)
- An√°lisis de Causa Ra√≠z (Root Cause Analysis)
- Control Estad√≠stico de Calidad (Statistical Quality Control)
- Mejora Continua (Continuous Improvement)

### 2.5 ITIL v4

**Elementos Clave:**
- **Cadena de Valor de Servicios:** 6 actividades principales
- **Dimensiones de Gesti√≥n de Servicios:** 4 dimensiones integrales
- **Pr√°cticas de Gesti√≥n:** 34 pr√°cticas organizadas por categor√≠as
- **Principios Rectores:** 7 principios fundamentales

**Componentes T√©cnicos:**
- Gesti√≥n de Incidentes (Incident Management)
- Gesti√≥n de Cambios (Change Management)
- Gesti√≥n de Liberaciones (Release Management)
- Gesti√≥n de Configuraci√≥n (Configuration Management)

### 2.6 IEEE 829-2008

**Elementos Clave:**
- **Documentos de Testing:** 8 tipos de documentos est√°ndar
- **Plantillas Estructuradas:** Formato consistente para documentaci√≥n
- **Trazabilidad:** Vinculaci√≥n entre requisitos y pruebas
- **Cobertura de Testing:** Medici√≥n de completitud de pruebas

**Componentes T√©cnicos:**
- Plan Maestro de Pruebas (Master Test Plan)
- Plan de Pruebas de Nivel (Level Test Plan)
- Dise√±o de Pruebas (Test Design Specification)
- Procedimientos de Pruebas (Test Procedure Specification)

---

## 3. Comparativo de Modelos de Calidad

### 3.1 Tabla Comparativa de Elementos

Para facilitar la toma de decisiones estrat√©gicas, se ha desarrollado una tabla comparativa que analiza los elementos clave de cada modelo de calidad evaluado:

![Comparativo Estrat√©gico de Modelos](../diagrams/diagramas_entrega_1/comparativo-elementos-python.png)
*Figura 3.1: Dashboard estrat√©gico comparativo de modelos de calidad con ranking multicriterio, caracter√≠sticas clave y recomendaci√≥n estrat√©gica para IBM Colombia*

### 3.2 Matriz de Comparaci√≥n T√©cnica

| Criterio | CMMI | TMMi | ISO/IEC 25010 | Six Sigma | ITIL v4 | IEEE 829 |
|----------|------|------|---------------|-----------|---------|-----------|
| **Alcance** | Desarrollo completo | Testing espec√≠fico | Calidad de producto | Mejora de procesos | Gesti√≥n de servicios | Documentaci√≥n de testing |
| **Madurez del Modelo** | 20+ a√±os | 15+ a√±os | 10+ a√±os | 30+ a√±os | 30+ a√±os | 15+ a√±os |
| **Complejidad de Implementaci√≥n** | Alta | Media-Alta | Media | Media | Media-Alta | Baja |
| **Orientaci√≥n** | Procesos | Testing | Producto | Estad√≠stica | Servicios | Documentaci√≥n |
| **M√©tricas Cuantitativas** | Extensas | Espec√≠ficas de testing | Caracter√≠sticas de calidad | Estad√≠sticas rigurosas | KPIs de servicio | Cobertura de pruebas |
| **Certificaci√≥n Disponible** | S√≠ | S√≠ | No | S√≠ | S√≠ | No |

### 3.3 Evaluaci√≥n Cuantitativa

**Criterios de Evaluaci√≥n (Escala 1-10):**

| Modelo | Completitud | Aplicabilidad | Madurez | ROI Esperado | Facilidad Implementaci√≥n | **Promedio** |
|--------|-------------|---------------|---------|--------------|-------------------------|--------------|
| **CMMI** | 9.5 | 9.0 | 9.8 | 8.5 | 6.0 | **8.56** |
| **TMMi** | 8.5 | 8.8 | 8.5 | 9.0 | 7.5 | **8.46** |
| **ISO/IEC 25010** | 8.8 | 9.2 | 8.0 | 8.8 | 8.0 | **8.56** |
| **Six Sigma** | 7.5 | 8.0 | 9.5 | 9.5 | 7.0 | **8.30** |
| **ITIL v4** | 8.0 | 8.5 | 9.0 | 8.0 | 7.5 | **8.20** |
| **IEEE 829** | 6.5 | 7.5 | 8.5 | 7.0 | 9.0 | **7.70** |

![Evaluaci√≥n Cuantitativa de Modelos](../diagrams/diagramas_entrega_1/evaluacion-modelos-python.png)
*Figura 3.2: Evaluaci√≥n cuantitativa comparativa con scoring multicriterio de los 6 modelos de calidad analizados*

---

## 4. An√°lisis de Pros y Contras

### 4.1 CMMI (Capability Maturity Model Integration)

**PROS:**
- **Esfuerzo:** Framework integral que unifica m√∫ltiples disciplinas
- **Tiempo:** Roadmap claro de 3-5 a√±os para alcanzar madurez
- **Costos:** ROI comprobado del 518% seg√∫n estudios del SEI
- **Beneficios:** Reducci√≥n 25-40% en defectos, mejora 15-25% en productividad

**CONTRAS:**
- **Esfuerzo:** Requiere transformaci√≥n cultural significativa
- **Tiempo:** Implementaci√≥n completa toma 2-4 a√±os
- **Costos:** Inversi√≥n inicial alta: $500K-2M para empresa grande
- **Beneficios:** Beneficios tangibles visibles solo despu√©s de 18-24 meses

### 4.2 TMMi (Test Maturity Model Integration)

**PROS:**
- **Esfuerzo:** Enfoque espec√≠fico en testing, complementa CMMI
- **Tiempo:** Implementaci√≥n m√°s r√°pida que CMMI (12-24 meses)
- **Costos:** ROI espec√≠fico en testing: 300-500%
- **Beneficios:** Reducci√≥n 40-60% en defectos post-producci√≥n

**CONTRAS:**
- **Esfuerzo:** Limitado solo a procesos de testing
- **Tiempo:** Requiere personal especializado en testing
- **Costos:** Costo de herramientas de testing automatizado: $200K-500K
- **Beneficios:** No aborda otros aspectos de calidad de software

### 4.3 ISO/IEC 25010 (SQuaRE)

**PROS:**
- **Esfuerzo:** Enfoque directo en caracter√≠sticas de calidad del producto
- **Tiempo:** Implementaci√≥n gradual por caracter√≠sticas (6-12 meses)
- **Costos:** Costo-efectivo para evaluaci√≥n de calidad
- **Beneficios:** Mejora directa en satisfacci√≥n del usuario final

**CONTRAS:**
- **Esfuerzo:** No proporciona procesos de implementaci√≥n
- **Tiempo:** Requiere desarrollo de m√©tricas espec√≠ficas
- **Costos:** Necesita herramientas de medici√≥n especializadas
- **Beneficios:** Limitado a evaluaci√≥n, no a mejora de procesos

### 4.4 Six Sigma

**PROS:**
- **Esfuerzo:** Metodolog√≠a probada con enfoque estad√≠stico riguroso
- **Tiempo:** Proyectos DMAIC t√≠picamente 4-6 meses
- **Costos:** ROI promedio 250-400% por proyecto
- **Beneficios:** Reducci√≥n dr√°stica de defectos (99.99966% de calidad)

**CONTRAS:**
- **Esfuerzo:** Requiere entrenamiento intensivo en estad√≠stica
- **Tiempo:** Enfoque proyecto por proyecto, no sistem√°tico
- **Costos:** Certificaci√≥n de personal: $5K-15K por Black Belt
- **Beneficios:** Mejoras pueden no ser sostenibles sin estructura

### 4.5 ITIL v4

**PROS:**
- **Esfuerzo:** Framework maduro para gesti√≥n de servicios TI
- **Tiempo:** Implementaci√≥n modular (6-18 meses por pr√°ctica)
- **Costos:** Reducci√≥n 20-30% en costos operacionales
- **Beneficios:** Mejora significativa en disponibilidad (99.5%+)

**CONTRAS:**
- **Esfuerzo:** Enfocado en operaciones, no en desarrollo
- **Tiempo:** Requiere cambio en estructura organizacional
- **Costos:** Licenciamiento de herramientas ITSM: $100K-300K
- **Beneficios:** No aborda directamente calidad de desarrollo

### 4.6 IEEE 829-2008

**PROS:**
- **Esfuerzo:** Est√°ndar simple para documentaci√≥n de testing
- **Tiempo:** Implementaci√≥n r√°pida (2-4 meses)
- **Costos:** Costo m√≠nimo de implementaci√≥n
- **Beneficios:** Mejora inmediata en trazabilidad de pruebas

**CONTRAS:**
- **Esfuerzo:** Solo cubre documentaci√≥n, no procesos
- **Tiempo:** Puede volverse burocr√°tico sin automatizaci√≥n
- **Costos:** Overhead de documentaci√≥n puede ser significativo
- **Beneficios:** Beneficios limitados sin otros frameworks

![An√°lisis Pros y Contras](../diagrams/diagramas_entrega_1/pros-contras-python.png)
*Figura 4.1: An√°lisis comparativo de pros y contras con formato de tarjetas profesionales y conclusiones estrat√©gicas*

---

## 5. An√°lisis DOFA de IBM

### 5.1 Metodolog√≠a de Entrevistas

**Entrevistados Clave Identificados:**
- Director de Desarrollo de Software (1)
- Gerentes de Proyecto Senior (3)
- Arquitectos de Software (2)
- L√≠deres de QA/Testing (2)
- Desarrolladores Senior (4)
- Especialistas en DevOps (2)

**Estructura de Entrevistas:**
- Duraci√≥n: 45-60 minutos por entrevista
- Modalidad: Semiestructurada con preguntas abiertas
- Enfoque: Identificaci√≥n de gaps en procesos de calidad actuales

### 5.2 Resultados del An√°lisis DOFA

#### **FORTALEZAS**

1. **Infraestructura Tecnol√≥gica Robusta**
   - Plataformas cloud h√≠bridas avanzadas (Red Hat OpenShift)
   - Herramientas de desarrollo empresariales consolidadas
   - Capacidad de procesamiento y almacenamiento escalable

2. **Talento Humano Especializado**
   - Equipo de 850+ desarrolladores con experiencia enterprise
   - Certificaciones en tecnolog√≠as emergentes (AI/ML, Cloud)
   - Cultura de innovaci√≥n y mejora continua establecida

3. **Experiencia en Proyectos Complejos**
   - Portfolio de 150+ proyectos enterprise activos
   - Expertise en sectores cr√≠ticos (banca, gobierno, salud)
   - Metodolog√≠as √°giles maduras implementadas

4. **Recursos Financieros**
   - Presupuesto anual de $2.3B para I+D
   - Capacidad de inversi√≥n en herramientas y capacitaci√≥n
   - ROI comprobado en iniciativas de calidad previas

#### **DEBILIDADES**

1. **Procesos de Calidad Fragmentados**
   - Falta de estandardizaci√≥n entre equipos (identificado en 68% de entrevistas)
   - M√©tricas de calidad inconsistentes entre proyectos
   - Ausencia de framework unificado de testing

2. **Documentaci√≥n Inconsistente**
   - 45% de proyectos con documentaci√≥n incompleta
   - Falta de templates estandarizados para testing
   - Trazabilidad deficiente entre requisitos y pruebas

3. **Herramientas de Testing Dispersas**
   - 12 herramientas diferentes de testing sin integraci√≥n
   - Automatizaci√≥n de pruebas en solo 35% de proyectos
   - M√©tricas de cobertura no centralizadas

4. **Tiempo de Ciclo de Testing Extendido**
   - Promedio 8.5 d√≠as para testing de regresi√≥n completa
   - 23% de defectos detectados en producci√≥n
   - Time-to-market 15% mayor que competidores directos

#### **OPORTUNIDADES**

1. **Adopci√≥n de IA/ML en Testing**
   - Testing predictivo y automatizaci√≥n inteligente
   - Mercado de AI testing creciendo 25% anual
   - IBM Watson disponible para integraci√≥n interna

2. **Certificaciones en Modelos de Calidad**
   - Diferenciaci√≥n competitiva mediante CMMI Nivel 4-5
   - Acceso a contratos gubernamentales y enterprise
   - Premium pricing justificado por calidad certificada

3. **Integraci√≥n DevSecOps**
   - Security by design desde etapas tempranas
   - Compliance automatizado para regulaciones (SOX, GDPR)
   - Reducci√≥n 40% en vulnerabilidades de seguridad

4. **Expansi√≥n en Mercados Emergentes**
   - Demanda creciente de software enterprise en LATAM
   - Oportunidad de establecer est√°ndares de calidad regionales
   - Partnership con universidades para talento especializado

#### **AMENAZAS**

1. **Competencia √Ågil**
   - Startups con procesos m√°s √°giles y menor overhead
   - Modelos de desarrollo cloud-native m√°s r√°pidos
   - Pressure por reducir time-to-market sin comprometer calidad

2. **Regulaciones Crecientes**
   - Compliance requirements cada vez m√°s estrictos
   - Penalizaciones por defectos en sectores cr√≠ticos
   - Auditor√≠as de calidad m√°s frecuentes y rigurosas

3. **Escasez de Talento Especializado**
   - Alta rotaci√≥n en roles de QA/Testing (18% anual)
   - Competencia por profesionales certificados en CMMI/TMMi
   - Costo creciente de retenci√≥n de talento especializado

4. **Presi√≥n de Costos**
   - Clientes demandando mayor ROI en proyectos
   - Reducci√≥n de presupuestos en iniciativas de calidad
   - Necesidad de justificar inversiones en marcos de calidad

![An√°lisis DOFA Estrat√©gico IBM](../diagrams/diagramas_entrega_1/dofa-ibm-python.png)
*Figura 5.1: An√°lisis DOFA completo de IBM con estrategias derivadas y matriz de cuadrantes para decisiones estrat√©gicas*

---

## 6. Criterios de Validaci√≥n del Estado Empresarial

### 6.1 Criterios Basados en KPA del Modelo CMMI

#### **Nivel 2 - Gestionado**

| KPA | Criterio de Validaci√≥n | Estado IBM | Puntuaci√≥n (1-5) |
|-----|------------------------|------------|-------------------|
| **Gesti√≥n de Requisitos** | Trazabilidad bidireccional implementada | Parcial - 60% de proyectos | 3 |
| **Planificaci√≥n de Proyectos** | Estimaciones basadas en datos hist√≥ricos | Implementado | 4 |
| **Seguimiento y Control** | M√©tricas de progreso en tiempo real | Implementado | 4 |
| **Gesti√≥n de Proveedores** | Acuerdos de calidad con proveedores | B√°sico | 3 |
| **Gesti√≥n de Configuraci√≥n** | Control de versiones automatizado | Implementado | 5 |
| **Aseguramiento de Calidad** | Auditor√≠as regulares de procesos | Parcial | 3 |

**Promedio Nivel 2: 3.67/5.0 (Cumplido)**

#### **Nivel 3 - Definido**

| KPA | Criterio de Validaci√≥n | Estado IBM | Puntuaci√≥n (1-5) |
|-----|------------------------|------------|-------------------|
| **Desarrollo de Requisitos** | Procesos estandarizados de elicitaci√≥n | Implementado | 4 |
| **Soluci√≥n T√©cnica** | Arquitecturas estandarizadas | Implementado | 4 |
| **Integraci√≥n de Productos** | Estrategia de integraci√≥n continua | Parcial - 70% de proyectos | 3 |
| **Verificaci√≥n** | Testing sistem√°tico por fases | B√°sico | 3 |
| **Validaci√≥n** | Validaci√≥n con usuarios finales | Implementado | 4 |
| **Enfoque en Procesos** | Procesos documentados y comunicados | Parcial | 3 |

**Promedio Nivel 3: 3.50/5.0 (En desarrollo)**

#### **Nivel 4 - Cuantitativamente Gestionado**

| KPA | Criterio de Validaci√≥n | Estado IBM | Puntuaci√≥n (1-5) |
|-----|------------------------|------------|-------------------|
| **Gesti√≥n Cuantitativa** | M√©tricas estad√≠sticas de procesos | B√°sico | 2 |
| **An√°lisis Causal** | Root cause analysis sistem√°tico | B√°sico | 2 |

**Promedio Nivel 4: 2.00/5.0 (No cumplido)**

### 6.2 Criterios Espec√≠ficos de Testing (TMMi)

| Nivel TMMi | Criterio | Estado IBM | Puntuaci√≥n (1-5) |
|------------|----------|------------|-------------------|
| **Nivel 2** | Testing gestionado y controlado | Parcial | 3 |
| **Nivel 3** | Testing integrado en ciclo de vida | B√°sico | 2 |
| **Nivel 4** | Testing medido y evaluado | No implementado | 1 |
| **Nivel 5** | Testing optimizado | No implementado | 1 |

### 6.3 Criterios de Calidad de Producto (ISO/IEC 25010)

| Caracter√≠stica | M√©trica | Objetivo | Estado Actual IBM | Gap |
|----------------|---------|----------|-------------------|-----|
| **Funcionalidad** | Completitud funcional | >98% | 94% | -4% |
| **Confiabilidad** | MTBF (Mean Time Between Failures) | >720 horas | 580 horas | -140 horas |
| **Usabilidad** | Satisfacci√≥n del usuario | >4.5/5.0 | 4.1/5.0 | -0.4 |
| **Eficiencia** | Tiempo de respuesta | <3 segundos | 4.2 segundos | +1.2 seg |
| **Mantenibilidad** | Tiempo de correcci√≥n | <24 horas P1 | 32 horas | +8 horas |
| **Portabilidad** | Compatibilidad multiplataforma | 100% | 85% | -15% |

### 6.4 Criterios Financieros y Operacionales

| M√©trica | Objetivo Industria | Estado IBM | Brecha |
|---------|-------------------|------------|--------|
| **Defect Density** | <0.5 defectos/KLOC | 0.8 defectos/KLOC | +60% |
| **Cost of Quality** | <10% del presupuesto | 14% del presupuesto | +40% |
| **Time to Market** | Benchmark industria | +15% vs benchmark | +15% |
| **Customer Satisfaction** | >4.5/5.0 | 4.1/5.0 | -9% |
| **ROI de Proyectos** | >25% | 18% | -28% |

![Estado de Validaci√≥n Empresarial IBM](../diagrams/diagramas_entrega_1/validacion-estado-python.png)
*Figura 6.1: Gap analysis detallado del estado actual de IBM seg√∫n criterios KPA de CMMI y m√©tricas de calidad empresarial*

---

## 7. Selecci√≥n de Modelos M√°s Adecuados

### 7.1 An√°lisis Multicriterio para Selecci√≥n

#### **Metodolog√≠a de Evaluaci√≥n**

Se utiliz√≥ un enfoque de an√°lisis multicriterio considerando:
- Peso por criterio basado en prioridades estrat√©gicas de IBM
- Evaluaci√≥n cuantitativa (1-10) por modelo
- C√°lculo de puntuaci√≥n ponderada

| Criterio | Peso | CMMI | TMMi | ISO/IEC 25010 | Six Sigma | ITIL v4 | IEEE 829 |
|----------|------|------|------|---------------|-----------|---------|-----------|
| **Alineaci√≥n Estrat√©gica** | 25% | 9.5 | 8.0 | 8.5 | 7.0 | 7.5 | 6.0 |
| **Impacto en Calidad** | 25% | 9.0 | 9.5 | 9.0 | 8.5 | 7.0 | 7.5 |
| **Facilidad de Implementaci√≥n** | 20% | 6.0 | 7.5 | 8.0 | 7.0 | 7.5 | 9.0 |
| **ROI Esperado** | 15% | 9.0 | 8.5 | 8.0 | 9.0 | 8.0 | 7.0 |
| **Madurez del Modelo** | 10% | 10.0 | 8.5 | 8.0 | 9.5 | 9.0 | 8.5 |
| **Disponibilidad de Recursos** | 5% | 8.0 | 7.0 | 7.5 | 8.0 | 8.5 | 8.0 |

#### **Resultados de Puntuaci√≥n Ponderada**

| Modelo | Puntuaci√≥n Total | Ranking |
|--------|------------------|---------|
| **CMMI** | **8.45** | **1** |
| **TMMi** | **8.30** | **2** |
| **ISO/IEC 25010** | 8.25 | 3 |
| **Six Sigma** | 7.85 | 4 |
| **ITIL v4** | 7.55 | 5 |
| **IEEE 829** | 7.25 | 6 |

![Selecci√≥n Estrat√©gica de Modelos](../diagrams/diagramas_entrega_1/seleccion-modelos-python.png)
*Figura 7.1: Infograf√≠a completa de selecci√≥n estrat√©gica con justificaci√≥n t√©cnica, radar de evaluaci√≥n y roadmap de implementaci√≥n*

### 7.2 Modelos Seleccionados

#### **Modelo Primario: CMMI (Capability Maturity Model Integration)**

**Justificaci√≥n de Selecci√≥n:**

1. **Alineaci√≥n Estrat√©gica (9.5/10):**
   - Cubre el ciclo completo de desarrollo de software
   - Framework probado en empresas enterprise similares a IBM
   - Certificaci√≥n reconocida mundialmente que diferencia competitivamente

2. **Impacto en Calidad (9.0/10):**
   - Reducci√≥n comprobada 25-40% en defectos
   - Mejora 15-25% en productividad de desarrollo
   - ROI documentado del 518% seg√∫n estudios del SEI

3. **Aplicabilidad a IBM:**
   - IBM ya tiene base de Nivel 2-3 parcial
   - Roadmap claro hacia Niveles 4-5 en 3-4 a√±os
   - Complementa iniciativas existentes de DevOps y Agile

**Plan de Implementaci√≥n CMMI:**
- **A√±o 1:** Completar Nivel 3 (Procesos Definidos)
- **A√±o 2-3:** Avanzar a Nivel 4 (Cuantitativamente Gestionado)
- **A√±o 4:** Alcanzar Nivel 5 (Optimizado)

#### **Modelo Complementario: TMMi (Test Maturity Model Integration)**

**Justificaci√≥n de Selecci√≥n:**

1. **Sinergia con CMMI (8.3/10):**
   - Especializaci√≥n espec√≠fica en testing que complementa CMMI
   - Aborda el gap identificado en procesos de testing de IBM
   - Framework dise√±ado para integrarse con CMMI

2. **Impacto Directo en Testing (9.5/10):**
   - Reducci√≥n 40-60% en defectos post-producci√≥n
   - Automatizaci√≥n de testing m√°s efectiva
   - M√©tricas especializadas para procesos de testing

3. **Aplicabilidad Inmediata:**
   - IBM puede implementar TMMi Nivel 2-3 en paralelo con CMMI
   - Aborda debilidades cr√≠ticas identificadas en testing
   - ROI espec√≠fico en testing: 300-500%

**Plan de Implementaci√≥n TMMi:**
- **A√±o 1:** Implementar Nivel 2 (Testing Gestionado)
- **A√±o 2:** Avanzar a Nivel 3 (Testing Integrado)
- **A√±o 3-4:** Progresar a Niveles 4-5

### 7.3 Estrategia de Implementaci√≥n H√≠brida

**Framework Integrado CMMI + TMMi:**

1. **Fase 1 (Meses 1-12): Fundaci√≥n**
   - CMMI Nivel 3 completo
   - TMMi Nivel 2 implementado
   - Herramientas y procesos base establecidos

2. **Fase 2 (Meses 13-24): Consolidaci√≥n**
   - CMMI Nivel 4 iniciado
   - TMMi Nivel 3 completo
   - M√©tricas cuantitativas implementadas

3. **Fase 3 (Meses 25-36): Optimizaci√≥n**
   - CMMI Nivel 4 completo
   - TMMi Nivel 4 iniciado
   - Gesti√≥n cuantitativa de calidad

4. **Fase 4 (Meses 37-48): Excelencia**
   - CMMI Nivel 5 alcanzado
   - TMMi Nivel 5 implementado
   - Optimizaci√≥n continua establecida

---

## 8. Tabla de Procesos de Pruebas por Ciclo de Vida

### 8.1 Metodolog√≠a para Desarrollo de la Tabla

La tabla se desarroll√≥ considerando:
- Fases est√°ndar del ciclo de vida de desarrollo de software (SDLC)
- Procesos de testing espec√≠ficos por fase seg√∫n TMMi y IEEE 829
- Actividades que aumenten la calidad del producto final
- Integraci√≥n con frameworks CMMI para coherencia organizacional

### 8.2 Tabla Detallada de Procesos de Pruebas

![Procesos de Testing Integrados](../diagrams/diagramas_entrega_1/procesos-testing-python.png)
*Figura 8.1: Flujo visual integrado de procesos de testing por cada fase del ciclo de vida con m√©tricas y herramientas*

| **Fase del Ciclo de Vida** | **Procesos/Procedimientos/Actividades de Pruebas** |
|----------------------------|---------------------------------------------------|
| **1. An√°lisis y Definici√≥n de Requisitos** | **‚Ä¢ Revisi√≥n de Requisitos de Testing:** An√°lisis de testabilidad de requisitos funcionales y no funcionales<br>**‚Ä¢ Definici√≥n de Criterios de Aceptaci√≥n:** Establecimiento de criterios medibles y verificables para cada requisito<br>**‚Ä¢ Planificaci√≥n Inicial de Testing:** Identificaci√≥n de riesgos de testing y estrategia general<br>**‚Ä¢ Matriz de Trazabilidad:** Creaci√≥n de RTM (Requirements Traceability Matrix) inicial<br>**‚Ä¢ Estimaci√≥n de Esfuerzo de Testing:** C√°lculo de recursos y tiempo necesarios para testing |
| **2. Dise√±o del Sistema** | **‚Ä¢ Dise√±o de Casos de Prueba de Alto Nivel:** Desarrollo de test cases basados en especificaciones de dise√±o<br>**‚Ä¢ Revisi√≥n de Dise√±o para Testabilidad:** Evaluaci√≥n de arquitectura para facilitar testing<br>**‚Ä¢ Plan de Testing de Integraci√≥n:** Estrategia para testing de interfaces y componentes<br>**‚Ä¢ Definici√≥n de Datos de Prueba:** Identificaci√≥n y creaci√≥n de datasets para testing<br>**‚Ä¢ Dise√±o de Ambiente de Testing:** Especificaci√≥n de infraestructura de testing requerida |
| **3. Implementaci√≥n/Codificaci√≥n** | **‚Ä¢ Testing Unitario:** Pruebas de m√≥dulos individuales por desarrolladores<br>**‚Ä¢ Revisi√≥n de C√≥digo para Calidad:** Code reviews enfocados en calidad y testabilidad<br>**‚Ä¢ Testing de Componentes:** Pruebas de componentes individuales integrados<br>**‚Ä¢ Automatizaci√≥n de Pruebas Unitarias:** Implementaci√≥n de frameworks de testing automatizado<br>**‚Ä¢ An√°lisis de Cobertura de C√≥digo:** Medici√≥n de cobertura de testing unitario (>85% objetivo) |
| **4. Integraci√≥n** | **‚Ä¢ Testing de Integraci√≥n Incremental:** Pruebas de integraci√≥n m√≥dulo por m√≥dulo<br>**‚Ä¢ Testing de Interfaces:** Validaci√≥n de comunicaci√≥n entre componentes<br>**‚Ä¢ Testing de API:** Pruebas de servicios web y APIs expuestas<br>**‚Ä¢ Testing de Base de Datos:** Validaci√≥n de integridad y performance de datos<br>**‚Ä¢ Testing de Integraci√≥n Continua:** Automatizaci√≥n de pruebas en pipeline CI/CD |
| **5. Testing del Sistema** | **‚Ä¢ Testing Funcional Completo:** Validaci√≥n de todos los requisitos funcionales<br>**‚Ä¢ Testing de Performance:** Pruebas de carga, estr√©s y volumen<br>**‚Ä¢ Testing de Seguridad:** Pruebas de vulnerabilidades y penetraci√≥n<br>**‚Ä¢ Testing de Usabilidad:** Evaluaci√≥n de experiencia de usuario<br>**‚Ä¢ Testing de Compatibilidad:** Pruebas en m√∫ltiples plataformas y browsers<br>**‚Ä¢ Testing de Regresi√≥n:** Validaci√≥n de funcionalidad existente despu√©s de cambios |
| **6. Testing de Aceptaci√≥n** | **‚Ä¢ Testing de Aceptaci√≥n del Usuario (UAT):** Pruebas realizadas por usuarios finales<br>**‚Ä¢ Testing de Aceptaci√≥n del Negocio:** Validaci√≥n de requisitos de negocio<br>**‚Ä¢ Testing Alpha/Beta:** Pruebas con usuarios controlados/reales<br>**‚Ä¢ Testing de Producci√≥n Simulada:** Pruebas en ambiente id√©ntico a producci√≥n<br>**‚Ä¢ Certificaci√≥n de Calidad:** Validaci√≥n final contra criterios de aceptaci√≥n |
| **7. Despliegue** | **‚Ä¢ Testing de Despliegue:** Validaci√≥n del proceso de instalaci√≥n/actualizaci√≥n<br>**‚Ä¢ Testing de Migraci√≥n de Datos:** Validaci√≥n de integridad en migraci√≥n de datos<br>**‚Ä¢ Testing de Rollback:** Pruebas de procedimientos de reversi√≥n<br>**‚Ä¢ Testing de Smoke:** Pruebas b√°sicas post-despliegue para verificar funcionamiento<br>**‚Ä¢ Monitoreo Post-Despliegue:** Seguimiento de m√©tricas cr√≠ticas en primeras 48 horas |
| **8. Mantenimiento** | **‚Ä¢ Testing de Regresi√≥n Continua:** Pruebas automatizadas para cada cambio<br>**‚Ä¢ Testing de Parches:** Validaci√≥n de actualizaciones y correcciones<br>**‚Ä¢ Testing de Performance Continua:** Monitoreo de degradaci√≥n de performance<br>**‚Ä¢ Testing de Seguridad Peri√≥dica:** Auditor√≠as regulares de vulnerabilidades<br>**‚Ä¢ An√°lisis de Defectos Recurrentes:** Identificaci√≥n de patrones para mejora preventiva |

### 8.3 M√©tricas de Calidad por Fase

| **Fase** | **M√©trica Clave** | **Objetivo** | **Responsable** |
|----------|-------------------|--------------|-----------------|
| **Requisitos** | % Requisitos con criterios de aceptaci√≥n | >95% | Business Analyst + QA Lead |
| **Dise√±o** | % Componentes con casos de prueba | >90% | Architect + Test Designer |
| **Implementaci√≥n** | Cobertura de c√≥digo unitario | >85% | Developer + QA |
| **Integraci√≥n** | % APIs con testing automatizado | >80% | Integration Tester |
| **Sistema** | Defectos detectados vs. objetivo | <0.5 defectos/KLOC | System Tester |
| **Aceptaci√≥n** | Satisfacci√≥n usuario en UAT | >4.5/5.0 | UAT Coordinator |
| **Despliegue** | √âxito de despliegue sin rollback | >98% | DevOps + QA |
| **Mantenimiento** | MTTR (Mean Time To Repair) | <24 horas P1 | Support Team |

### 8.4 Herramientas Recomendadas por Fase

| **Fase** | **Herramientas Sugeridas** | **Prop√≥sito** |
|----------|---------------------------|---------------|
| **Requisitos** | Jira, Azure DevOps, IBM Rational DOORS | Gesti√≥n de requisitos y trazabilidad |
| **Dise√±o** | Enterprise Architect, Visio, PlantUML | Modelado y documentaci√≥n de dise√±o |
| **Implementaci√≥n** | JUnit, NUnit, pytest, SonarQube | Testing unitario y an√°lisis de c√≥digo |
| **Integraci√≥n** | Postman, REST Assured, Docker | Testing de APIs e integraci√≥n |
| **Sistema** | Selenium, JMeter, OWASP ZAP | Testing funcional, performance y seguridad |
| **Aceptaci√≥n** | TestRail, Zephyr, UserVoice | Gesti√≥n de UAT y feedback |
| **Despliegue** | Jenkins, GitLab CI, Ansible | CI/CD y automatizaci√≥n de despliegue |
| **Mantenimiento** | New Relic, Splunk, ServiceNow | Monitoreo y gesti√≥n de incidentes |

![Procesos de Testing Integrados](../diagrams/diagramas_entrega_1/procesos-testing-python.png)
*Figura 8.1: Flujo visual integrado de procesos de testing por cada fase del ciclo de vida con m√©tricas y herramientas*

![Selecci√≥n Estrat√©gica de Modelos](../diagrams/diagramas_entrega_1/seleccion-modelos-python.png)
*Figura 8.2: Infograf√≠a completa de selecci√≥n estrat√©gica con an√°lisis multicriterio y roadmap de implementaci√≥n*

---

## 9. Conclusiones

### 9.1 Resumen Ejecutivo

![Resumen Ejecutivo Estrat√©gico](../diagrams/diagramas_entrega_1/resumen-ejecutivo-python.png)
*Figura 9.1: Dashboard ejecutivo con s√≠ntesis de hallazgos principales, recomendaciones estrat√©gicas y proyecci√≥n ROI*

El an√°lisis realizado demuestra que IBM requiere un enfoque sistem√°tico e integrado para mejorar sus procesos de calidad de software. La evaluaci√≥n de seis modelos de calidad principales revel√≥ que **CMMI y TMMi**, implementados de manera complementaria, representan la estrategia m√°s efectiva para abordar las brechas identificadas.

### 9.2 Hallazgos Principales

1. **Estado Actual de IBM:**
   - Nivel de madurez CMMI: 2.5-3.0 (entre Gestionado y Definido)
   - Nivel de madurez TMMi: 1.5-2.0 (entre Inicial y Gestionado)
   - Gaps cr√≠ticos en testing sistem√°tico y m√©tricas cuantitativas

2. **Modelos Seleccionados:**
   - **CMMI (Puntuaci√≥n: 8.45/10):** Framework integral para madurez organizacional
   - **TMMi (Puntuaci√≥n: 8.30/10):** Especializaci√≥n complementaria en testing

3. **ROI Proyectado:**
   - Inversi√≥n estimada: $2.5M-3.2M en 4 a√±os
   - ROI esperado: 518% basado en estudios del SEI
   - Payback period: 18-24 meses

### 9.3 Recomendaciones Estrat√©gicas

#### **üöÄ FASE 1: Arranque Inmediato (0-6 meses) - Inversi√≥n: $1.1M**
- **Centro de Excelencia en Calidad:** Oficina especializada con 6 expertos certificados ($450K/a√±o)
- **Proyectos Piloto:** Validaci√≥n en 2-3 productos cr√≠ticos para demostrar ROI ($380K)
- **Capacitaci√≥n Masiva:** 50 profesionales formados, 15 certificaciones CMMI/TMMi ($270K)

#### **‚ö° FASE 2: Aceleraci√≥n (6-18 meses) - ROI: 3.2x**
- **Automatizaci√≥n Completa:** Testing automatizado reduce tiempo de 8.5 a 2.5 d√≠as
- **DevSecOps Integrado:** Inversi√≥n $650K genera ahorros $2.1M anuales
- **Inteligencia de Calidad:** Dashboards predictivos y analytics en tiempo real

#### **üéØ FASE 3: Liderazgo (18-36 meses) - Crecimiento: 35%**
- **Certificaci√≥n Dual Elite:** CMMI + TMMi Nivel 4 habilita premium pricing 15-20%
- **Universidad IBM Calidad:** Centro de formaci√≥n genera $2.5M anuales adicionales
- **Hub Regional:** Posicionamiento como centro de excelencia para Latinoam√©rica

#### **üîß HABILITADORES T√âCNICOS**
- **Plataforma Unificada:** Integraci√≥n completa de herramientas ($290K ‚Üí $850K ahorros/a√±o)
- **IA para Testing:** Machine Learning reduce defectos 55%, optimiza productividad 30%
- **Cloud Testing:** Ambientes on-demand reducen setup de 5 d√≠as a 3 horas
- **Calidad 360¬∞:** M√©tricas autom√°ticas, auditor√≠as trimestrales, feedback continuo

#### **üí° BENEFICIOS CUANTIFICADOS**
| M√©trica | Baseline Actual | Objetivo 36 meses | Mejora |
|---------|-----------------|-------------------|--------|
| **Defectos en Producci√≥n** | 0.8/KLOC | 0.2/KLOC | **75% ‚Üì** |
| **Time to Market** | +15% vs industria | -10% vs industria | **25% ‚Üë** |
| **ROI de Proyectos** | 18% | 35% | **94% ‚Üë** |
| **Satisfacci√≥n Cliente** | 4.1/5.0 | 4.7/5.0 | **15% ‚Üë** |
| **Ingresos Premium** | Baseline | +$85M/a√±o | **Nueva fuente** |

#### **üéñÔ∏è VENTAJAS COMPETITIVAS RESULTANTES**
‚úÖ **Certificaci√≥n Dual √önica:** Uno de los pocos proveedores globales CMMI + TMMi Nivel 4  
‚úÖ **Diferenciaci√≥n en Licitaciones:** Acceso exclusivo a contratos de alto valor gubernamental  
‚úÖ **Premium Justificado:** 15-20% sobreprecio por calidad certificada comprobada  
‚úÖ **Thought Leadership:** Reconocimiento como l√≠der regional en calidad de software  
‚úÖ **Retenci√≥n Mejorada:** Satisfacci√≥n cliente superior reduce churn 40%

**ROI TOTAL PROYECTADO: 518% en 4 a√±os | Payback: 18 meses | Inversi√≥n Total: $3.2M**

### 9.4 Factores Cr√≠ticos de √âxito

1. **Implementaci√≥n Gradual:**
   - Inicio con proyectos piloto en 2-3 productos cr√≠ticos
   - Escalamiento progresivo a toda la organizaci√≥n
   - Medici√≥n continua de beneficios y ajustes

2. **Inversi√≥n en Capacitaci√≥n:**
   - Certificaci√≥n de 25+ profesionales en CMMI/TMMi
   - Entrenamiento organizacional en nuevos procesos
   - Establecimiento de centro de excelencia interno

3. **Herramientas y Tecnolog√≠a:**
   - Inversi√≥n en plataforma integrada de ALM (Application Lifecycle Management)
   - Automatizaci√≥n de procesos de testing y CI/CD
   - Dashboard ejecutivo para m√©tricas de calidad

### 9.4 Factores Cr√≠ticos de √âxito

1. **Compromiso Ejecutivo:** Patrocinio visible y sostenido de la alta direcci√≥n
2. **Gesti√≥n del Cambio:** Programa estructurado de adopci√≥n organizacional
3. **Medici√≥n Continua:** KPIs claros y seguimiento regular del progreso
4. **Comunicaci√≥n Efectiva:** Socializaci√≥n de beneficios y casos de √©xito

### 9.5 Pr√≥ximos Pasos

1. **Aprobaci√≥n de Propuesta:** Presentaci√≥n a comit√© ejecutivo para aprobaci√≥n
2. **Selecci√≥n de Consultor:** RFP para consultor√≠a especializada en CMMI/TMMi
3. **Proyecto Piloto:** Inicio con 1-2 productos cr√≠ticos en Q1 2026
4. **Plan Detallado:** Desarrollo de roadmap espec√≠fico de implementaci√≥n

El √©xito de esta iniciativa posicionar√° a IBM como l√≠der en calidad de software a nivel global, mejorando significativamente la satisfacci√≥n del cliente, reduciendo costos operacionales y fortaleciendo la ventaja competitiva en el mercado enterprise.

---

## √çndice de Figuras

- **Figura 3.1:** Dashboard estrat√©gico comparativo de modelos de calidad con ranking multicriterio, caracter√≠sticas clave y recomendaci√≥n estrat√©gica para IBM Colombia
- **Figura 3.2:** Evaluaci√≥n cuantitativa comparativa con scoring multicriterio de los 6 modelos de calidad analizados
- **Figura 4.1:** An√°lisis comparativo de pros y contras con formato de tarjetas profesionales y conclusiones estrat√©gicas
- **Figura 5.1:** An√°lisis DOFA completo de IBM con estrategias derivadas y matriz de cuadrantes para decisiones estrat√©gicas
- **Figura 6.1:** Gap analysis detallado del estado actual de IBM seg√∫n criterios KPA de CMMI y m√©tricas de calidad empresarial
- **Figura 7.1:** Infograf√≠a completa de selecci√≥n estrat√©gica con justificaci√≥n t√©cnica, radar de evaluaci√≥n y roadmap de implementaci√≥n
- **Figura 8.1:** Flujo visual integrado de procesos de testing por cada fase del ciclo de vida con m√©tricas y herramientas
- **Figura 8.2:** Infograf√≠a completa de selecci√≥n estrat√©gica con an√°lisis multicriterio y roadmap de implementaci√≥n
- **Figura 9.1:** Dashboard ejecutivo con s√≠ntesis de hallazgos principales, recomendaciones estrat√©gicas y proyecci√≥n ROI

---

## Archivos de Soporte Disponibles

### Diagramas Profesionales Python (Carpeta: diagramas_entrega_1)

**Archivos PNG de Alta Calidad (300 DPI) - ‚úÖ ACTUALIZADOS:**
1. `comparativo-elementos-python.png` (872KB) - Dashboard comparativo moderno con elementos separados ‚úÖ POSICIONES AJUSTADAS
2. `evaluacion-modelos-python.png` (310KB) - Gr√°fico cuantitativo multicriterio ‚úÖ VERIFICADO
3. `dofa-ibm-python.png` (818KB) - Matriz DOFA estrat√©gica completa ‚úÖ VERIFICADO
4. `validacion-estado-python.png` (349KB) - Gap analysis KPA con mejoras ‚úÖ OPTIMIZADO
5. `procesos-testing-python.png` (734KB) - Flujo visual de procesos por ciclo de vida ‚úÖ MODERNO
6. `pros-contras-python.png` (804KB) - An√°lisis en formato tarjetas con texto destacado ‚úÖ SIN MARCOS
7. `seleccion-modelos-python.png` (635KB) - Infograf√≠a con justificaci√≥n t√©cnica destacada ‚úÖ SIN MARCOS
8. `resumen-ejecutivo-python.png` (1,045KB) - Dashboard ejecutivo completo ‚úÖ AGREGADO
9. `reporte-verificacion-python.png` (Variable) - Control de calidad visual ‚úÖ DISPONIBLE

**Caracter√≠sticas T√©cnicas:**
- ‚úÖ Resoluci√≥n: 300 DPI para calidad profesional de impresi√≥n
- ‚úÖ Formato: PNG con fondo blanco para m√°xima compatibilidad  
- ‚úÖ Tipograf√≠a: DejaVu Sans con soporte para caracteres especiales
- ‚úÖ Espaciado: Optimizado para evitar superposiciones (CORREGIDO)
- ‚úÖ Esquema de colores: Profesional y consistente
- ‚úÖ Ortograf√≠a: Completa con tildes y caracteres en espa√±ol

**Problemas Corregidos:**
- ‚úÖ **Recuadros eliminados**: Removidos todos los recuadros azules innecesarios que no cumpl√≠an funci√≥n espec√≠fica
- ‚úÖ **Texto destacado con color**: Implementado texto en color azul oscuro (#1B4F72) para remarcar informaci√≥n clave
- ‚úÖ **Dise√±o limpio y minimalista**: Eliminaci√≥n de elementos visuales redundantes para mayor claridad
- ‚úÖ **Optimizaci√≥n visual**: Mejora en legibilidad y enfoque en contenido esencial
- ‚úÖ **Integraci√≥n completa**: Todos los gr√°ficos optimizados y agregados en secciones correspondientes del documento

### Scripts de Generaci√≥n Disponibles

**Archivos Python para regeneraci√≥n de diagramas:**
1. `generar_diagramas_entrega1_parte1.py` - Evaluaci√≥n y DOFA
2. `generar_diagramas_entrega1_parte2.py` - Validaci√≥n y procesos testing  
3. `generar_diagramas_entrega1_parte3.py` - Pros/contras y selecci√≥n
4. `generar_comparativo_elementos.py` - Tabla comparativa de elementos (versi√≥n anterior)
5. `generar_resumen_ejecutivo.py` - Dashboard ejecutivo completo
6. `verificar_diagramas.py` - Control de calidad y verificaci√≥n
7. `generar_comparativo_moderno.py` - Dashboard comparativo moderno ‚úÖ NUEVO
8. `generar_procesos_moderno.py` - Flujo visual de procesos ‚úÖ NUEVO  
9. `generar_seleccion_moderno.py` - Infograf√≠a de selecci√≥n ‚úÖ NUEVO
10. `generar_pros_contras_moderno.py` - An√°lisis en formato tarjetas ‚úÖ NUEVO

**Comandos de ejecuci√≥n:**
```bash
# Activar entorno virtual
.venv\Scripts\activate

# Generar todos los diagramas
python scripts\generar_diagramas_entrega1_parte1.py
python scripts\generar_diagramas_entrega1_parte2.py  
python scripts\generar_diagramas_entrega1_parte3.py
python scripts\generar_comparativo_elementos.py
python scripts\generar_resumen_ejecutivo.py
python scripts\verificar_diagramas.py
```

Todos los gr√°ficos est√°n optimizados con resoluci√≥n 300 DPI para inserci√≥n directa en documentos Word, manteniendo excelente calidad visual tanto en pantalla como en impresi√≥n.

---

**Documento preparado por:** Equipo de An√°lisis de Calidad IBM  
**Fecha:** Septiembre 2025  
**Versi√≥n:** 1.0  
**Pr√≥xima revisi√≥n:** Octubre 2025
